{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ling 380 - Week 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship attribution and style analysis\n",
    "\n",
    "This is a very general area of study that can help you figure out who wrote what, but also the differences among authors. Authorship attribution is quite popular in literature, for instance, determining if an anonymous piece of fiction was written by a famous author, based on that author's published work. That's, in part, how it was discovered that ['The Cuckoo's Calling', by one Robert Galbraith, was, in fact, the work of J.K. Rowling](https://www.scientificamerican.com/article/how-a-computer-program-helped-show-jk-rowling-write-a-cuckoos-calling/). Authorship attribution is one of the subfields within [forensic linguistics](https://en.wikipedia.org/wiki/Forensic_linguistics).\n",
    "\n",
    "More generally, the method can be applied to investigate the style of a text, to figure out how complex it is, or what other characteristics it has, a field known as [stylometry](https://en.wikipedia.org/wiki/Stylometry). \n",
    "\n",
    "To figure out the characteristics of text, and, more importantly, to distinguish the style of different authors, we can use different measures. Among the most common are:\n",
    "\n",
    "* Word length\n",
    "  * Average frequency, or frequency distribution. This may distinguish authors that like long words. In English, this usually means words of Latinate origin. So this tells us something about the vocabulary of an author. \n",
    "* Most common words\n",
    "  * Some authors just like to use the same set of words often. This one is a bit tricky, because most common words may also have to do with the topic of the text, not with the author.\n",
    "* Function words\n",
    "  * Function words, or stopwords, are sometimes idiosynchratic. Some authors love to use _nonetheless_. Others prefer _nevertheless_. Some authors use a lot of _so_; others _but_ or _if_\n",
    "  * Related, sometimes punctuation is an interesting marker of style. Do you use semi-colons often? Most people don't, but if you do, it's a tell.\n",
    "* Parts of speech\n",
    "  * Relative use of nouns, verbs, adverbs, etc. [Adverbs](https://www.livemint.com/Leisure/i8wjh4uNOfjbcZNuVvMPQM/The-adverbs-that-gave-JK-Rowling-away.html) were one of the characteristics of J.K. Rowling's style that tied her to Robert Galbraith.\n",
    "* Statistical similarity\n",
    "  * Various methods of statististical similarity across texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style comparison\n",
    "\n",
    "The code below comes from the book [Real World Python](https://nostarch.com/real-world-python/) and the book's [repository](https://github.com/rlvaugh/Real_World_Python/tree/master).\n",
    "\n",
    "We will compare three things in three different books:\n",
    "* Word length\n",
    "* Stop word use\n",
    "* Part of speech tags\n",
    "\n",
    "The books for this notebook are in the directory 'reviews'. They are:\n",
    "\n",
    "* [The Hound of the Baskervilles](https://www.gutenberg.org/ebooks/3070), by Arthur Conan Doyle, detective novel\n",
    "* [The War of the Worlds](https://www.gutenberg.org/ebooks/26291), by H.G. Wells, science fiction\n",
    "* [The Lost World](https://www.gutenberg.org/ebooks/139), also by Arthur Conan Doyle, science fiction\n",
    "\n",
    "One of the points of this exercise is to see whether the genre (detective novel vs. science fiction) or the author's style (Doyle vs. Wells) helps group the books differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all the functions\n",
    "These are a bit complex, but mostly because they produce the plots, using [matplotlib](https://matplotlib.org/), a visualization library. You can try and play with some of the parameters in the functions to produce different graphs, for instance, changing the colours, the distance between bars, or the type of graph (bars or plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_string(filename):\n",
    "    \"\"\"Read a text file and return a string.\"\"\"\n",
    "    with open(filename) as infile:\n",
    "        return infile.read()\n",
    "    \n",
    "def make_word_dict(strings_by_author):\n",
    "    \"\"\"Return dictionary of tokenized words by corpus by author.\"\"\"\n",
    "    words_by_author = dict()\n",
    "    for author in strings_by_author:\n",
    "        tokens = nltk.word_tokenize(strings_by_author[author])\n",
    "        words_by_author[author] = ([token.lower() for token in tokens\n",
    "                                    if token.isalpha()])\n",
    "    return words_by_author\n",
    "\n",
    "def find_shortest_corpus(words_by_author):\n",
    "    \"\"\"Return length of shortest corpus.\"\"\"\n",
    "    word_count = []\n",
    "    for author in words_by_author:\n",
    "        word_count.append(len(words_by_author[author]))\n",
    "        print('Number of words for {} = {}'.\n",
    "              format(author, len(words_by_author[author])))\n",
    "    len_shortest_corpus = min(word_count)\n",
    "    print('length shortest corpus = {}'.format(len_shortest_corpus))        \n",
    "    return len_shortest_corpus    \n",
    "\n",
    "def word_length_test(words_by_author, len_shortest_corpus):\n",
    "    \"\"\"Plot word length freq by author, truncated to shortest corpus length, all together with bars next to each other.\"\"\"\n",
    "    by_author_length_freq_dist = dict()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))  # You can adjust the figure size if needed\n",
    "\n",
    "    all_word_lengths = set()\n",
    "    for author in words_by_author:\n",
    "        word_lengths = [len(word) for word in words_by_author[author][:len_shortest_corpus]]\n",
    "        all_word_lengths.update(word_lengths)\n",
    "    \n",
    "    all_word_lengths = sorted(list(all_word_lengths)) \n",
    "\n",
    "    bar_width = 0.2\n",
    "\n",
    "    for i, author in enumerate(words_by_author):\n",
    "        word_lengths = [len(word) for word in words_by_author[author][:len_shortest_corpus]]\n",
    "        \n",
    "        freq_dist = nltk.FreqDist(word_lengths)\n",
    "\n",
    "        x = [length for length in all_word_lengths]\n",
    "        y = [freq_dist[length] for length in all_word_lengths] \n",
    "\n",
    "        shifted_x = [length + i * bar_width for length in x] \n",
    "\n",
    "        plt.bar(shifted_x, y, label=author, alpha=0.7, width=bar_width)\n",
    "\n",
    "    plt.title('Word length frequency distribution')\n",
    "    plt.xlabel('Word length')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xticks(all_word_lengths)\n",
    "    plt.show()\n",
    "\n",
    "def stopwords_test(words_by_author, len_shortest_corpus, top_n=30):\n",
    "    \"\"\"Plot most frequent stopwords by author, truncated to shortest corpus length.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    stopword_labels = stop_words[:30]\n",
    "\n",
    "    for i, author in enumerate(words_by_author):\n",
    "        stopwords_by_author = [word for word in words_by_author[author]\n",
    "                               [:len_shortest_corpus] if word in stop_words]\n",
    "\n",
    "        stopword_counts = Counter(stopwords_by_author)     \n",
    "        top_stopwords = stopword_counts.most_common(top_n)\n",
    "        if not top_stopwords:\n",
    "            continue\n",
    "        top_k, top_v = zip(*top_stopwords)\n",
    "        shifted_x = np.arange(len(top_k)) + (i * 0.2)\n",
    "        plt.bar(shifted_x, top_v, label=author, width=0.4, alpha=1)\n",
    "        \n",
    "    plt.xticks(np.arange(len(stopword_labels)), stopword_labels, rotation=90)\n",
    "    plt.xlabel('Stopword')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Most frequent stopwords by author (Top {top_n})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def parts_of_speech_test(words_by_author, len_shortest_corpus):\n",
    "    \"\"\"Plot author use of parts-of-speech such as nouns, verbs, adverbs, etc.\"\"\"\n",
    "    fdist = dict()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for i, author in enumerate(words_by_author):\n",
    "        pos_by_author = [pos[1] for pos in nltk.pos_tag(words_by_author[author][:len_shortest_corpus])]\n",
    "        fdist[author] = Counter(pos_by_author)\n",
    "        k, v = list(fdist[author].keys()), list(fdist[author].values())\n",
    "        plt.plot(k, v, linestyle='', marker='^', label=author, markersize=10)\n",
    "\n",
    "    plt.title('Part of speech by author')\n",
    "    plt.xlabel('Parts of speech')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Authors', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to where your files are\n",
    "path = './authorship'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of strings by author from all text files in the directory\n",
    "strings_by_author = {}\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.txt'):  # Make sure it's a .txt file\n",
    "        author_name = os.path.splitext(filename)[0]  # Use filename as the author name\n",
    "        strings_by_author[author_name] = text_to_string(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize texts\n",
    "words_by_author = make_word_dict(strings_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the shortest book\n",
    "# we'll truncate them all to this length\n",
    "len_shortest_corpus = find_shortest_corpus(words_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the length of words\n",
    "word_length_test(words_by_author, len_shortest_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the use of stopwords\n",
    "stopwords_test(words_by_author, len_shortest_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the frequency of parts of speech\n",
    "parts_of_speech_test(words_by_author, len_shortest_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We have learned about authorship attribution and some techniques to calculate differences across authors. We have also learned to produce visualizations using matplotlib."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
