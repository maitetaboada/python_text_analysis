
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Ling 380 - Week 8 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Week_08';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ling 380 - Week 9" href="Week_09.html" />
    <link rel="prev" title="Ling 380 - Week 7" href="Week_07.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Week_01.html">Ling380 - Week 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="Week_02.html">Ling380 - Week 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Week_03.html">Ling 380 - Week 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="Week_04.html">Ling 380 - Week 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="Week_05.html">Ling 380 - Week 5</a></li>

<li class="toctree-l1"><a class="reference internal" href="Week_06.html">Ling 380 - Week 6</a></li>




<li class="toctree-l1"><a class="reference internal" href="Week_07.html">Ling 380 - Week 7</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Ling 380 - Week 8</a></li>



<li class="toctree-l1"><a class="reference internal" href="Week_09.html">Ling 380 - Week 9</a></li>



<li class="toctree-l1"><a class="reference internal" href="Week_10.html">Ling 380 - Week 10</a></li>



<li class="toctree-l1"><a class="reference internal" href="Week_11.html">Ling 380 - Week 11</a></li>




<li class="toctree-l1"><a class="reference internal" href="Week_12.html">Ling 380 - Week 12</a></li>


<li class="toctree-l1"><a class="reference internal" href="Week_13.html">Ling 380 - Week 13</a></li>


<li class="toctree-l1"><a class="reference internal" href="nltk_install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="spacy_install.html">Installing spaCy</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FWeek_08.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Week_08.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Ling 380 - Week 8</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Ling 380 - Week 8</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-ai">Generative AI</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-ngrams">Calculating ngrams</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-statements">Import statements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nltk-ngram-functions">NLTK ngram functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-ngram-frequencies-from-reuters">Calculating ngram frequencies from Reuters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-data-to-create-ngrams">Import data to create ngrams</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-and-use-a-function-to-clean-the-text">Define and use a function to clean the text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-everygrams-and-create-a-dictionary">Run everygrams and create a dictionary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warning">Warning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-text-from-the-word-salad-lists">Generating text from the word salad lists</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ling-380-week-8">
<h1>Ling 380 - Week 8<a class="headerlink" href="#ling-380-week-8" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="generative-ai">
<h1>Generative AI<a class="headerlink" href="#generative-ai" title="Link to this heading">#</a></h1>
<p>Generative Artificial Intelligence refers to a class of methods and algorithms that use Large Language Models to <strong>generate</strong> text. The most common way we experience that generative capacity is with models like ChatGPT, where we give it an input and it generates an answer.</p>
<p>There are tons of good explanations out there for these models. Terms that you should understand are:</p>
<ul class="simple">
<li><p>Artificial intelligence (AI) - an attempt to model human intelligence</p></li>
<li><p>Machine learning (ML) - learning to identify patterns in data, usually to identify (predict) new patterns in new data</p></li>
<li><p>Neural machine learning, neural models - a class of ML models that take as inspiration the structure of the human brain (neurons and connections)</p></li>
<li><p>Deep learning - a class of ML models that use neural models, with several layers of ‘neurons’, and a depth of several layers</p></li>
<li><p>Large language models (LLMs) - models of language based on the principle of sequences: You can predict the next word/token based on the previous word(s).</p></li>
<li><p>Generative AI - models that predict the next word based on LLMs</p></li>
</ul>
<p>We are dealing with language in this course, which is why I talk about predicting the next word or token. Generative AI also works for images, video, code, and other types of data.</p>
<p>The basic principle behind most modern Generative AI models is a classic saying from linguist <a class="reference external" href="https://en.wikipedia.org/wiki/John_Rupert_Firth">J.R. Firth</a> (1890-1960): “you shall know a word by the company it keeps”. Originally, this meant that you can understand <a class="reference external" href="https://ecampusontario.pressbooks.pub/essentialsoflinguistics2/chapter/7-5-lexical-meaning/">the meaning of a word</a> by looking at the sentences or context it appears in. In modern NLP and LLMs, it means that we can create a model of language based on <a class="reference external" href="http://glottopedia.org/index.php/Collocation"><strong>collocation</strong></a>, the way that words occur together.</p>
<p>A language model is just the encoding of knowledge about likely sequences and word associations. You can create a language model by obtaining statistics about a large corpus of language. You can also create a large language model (LLM) like the ones behind ChatGPT or Llama using deep learning.</p>
<p>To understand this, we are going to work with <strong>ngrams</strong> (also spelled n-grams). Ngrams are sequences of tokens (usually words, but sometimes also punctuation) of size <em>n</em>. Terms:</p>
<ul class="simple">
<li><p>ngram / unigram - one token/word</p></li>
<li><p>bigram / 2-gram - sequence of two tokens</p></li>
<li><p>trigram / 3-gram - sequence of three tokens</p></li>
<li><p>4-gram - sequence of four tokens</p></li>
<li><p>etc.</p></li>
</ul>
<p>We’ll create simple language models from ngrams using NLTK. The intuition about n-grams is that you can predict the next <em>n</em> in a sequence if you know the frequencies of pairs of <em>n</em> items from corpora. To make things simple, let’s think of <em>n</em> as 2. And we will assume <em>n</em> is a word. But you can also calculate ngram frequency for characters, sounds, or sentences.</p>
<p>Thus, we can figure out what the next word is if we know the previous words are. Let’s say that we want to find out the likelihood that the next word in the sequence <em>I really like</em> is <em>you</em>. This is, by the way, what Google suggested when I typed <em>I really like…</em> The first link was to a <a class="reference external" href="https://youtu.be/qV5lzRHrGeg">Carly Rae Jepsen song</a>. We can calculate that as:</p>
<div class="math notranslate nohighlight">
\[ P(you | I, really, like ) \]</div>
<p>The way that formula is written is a 4-gram (a sequence of 4 words). This can be difficult to calculate, especially for less frequent combinations of sentences. So, to make this into a bigram probability, we calculate the following, which reads as “the probability of <em>you</em> given <em>like</em>”:</p>
<div class="math notranslate nohighlight">
\[ P(you | like ) \]</div>
<p>The general formula is below. The probability of <span class="math notranslate nohighlight">\(w_i\)</span> given the sequence <span class="math notranslate nohighlight">\(w_1\)</span> to <span class="math notranslate nohighlight">\(w_{i-1}\)</span> is approximately the probability of  <span class="math notranslate nohighlight">\(w_i\)</span> given <span class="math notranslate nohighlight">\(w_{i-1}\)</span>. So, instead of calculating probabilities for a long sequence of words, we do it for a sequence of 2 words at a time.</p>
<div class="math notranslate nohighlight">
\[ P(w_i | w_1, w_2, w_3, ..., w_{i-1} ) \approx P(w_i | w_{i-1}) \]</div>
<p>Note that above we say “the probability of <em>x</em> given <em>y</em>”. To calculate that, we just count how often any 2 words appear in a large enough corpus. This is what we’ll do in this notebook!</p>
<p>Credits: <a class="reference external" href="https://github.com/nltk/nltk/blob/develop/nltk/lm/__init__.py">NLTK LM documentation</a>, <a class="reference external" href="https://www.kaggle.com/code/alvations/n-gram-language-model-with-nltk">N-gram language models</a>, <a class="reference external" href="https://www.geeksforgeeks.org/n-gram-language-modelling-with-nltk/">N-gram language modelling with NLTK</a>, <a class="reference external" href="https://stackoverflow.com/questions/75565130/predicting-next-word-using-n-gram-model-nltk">Predicting next word using n-gram model NLTK</a>.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="calculating-ngrams">
<h1>Calculating ngrams<a class="headerlink" href="#calculating-ngrams" title="Link to this heading">#</a></h1>
<section id="import-statements">
<h2>Import statements<a class="headerlink" href="#import-statements" title="Link to this heading">#</a></h2>
<p>We import everything we need, including bits of NLTK. To train only on “important” or content words, we will remove punctuation and <a class="reference external" href="https://en.wikipedia.org/wiki/Stop_word">stopwords</a>. We’ll use the <a class="reference external" href="https://www.nltk.org/book/ch02.html#reuters-corpus">NLTK Reuters corpus</a> to train, so we need to import that too.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">string</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.corpus</span><span class="w"> </span><span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.util</span><span class="w"> </span><span class="kn">import</span> <span class="n">bigrams</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.util</span><span class="w"> </span><span class="kn">import</span> <span class="n">ngrams</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.util</span><span class="w"> </span><span class="kn">import</span> <span class="n">everygrams</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.corpus</span><span class="w"> </span><span class="kn">import</span> <span class="n">reuters</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">FreqDist</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span><span class="p">,</span> <span class="n">sent_tokenize</span> 
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span> 
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span> 
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;reuters&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to
[nltk_data]     /Users/yifangyuan/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     /Users/yifangyuan/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package reuters to
[nltk_data]     /Users/yifangyuan/nltk_data...
[nltk_data]   Package reuters is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="nltk-ngram-functions">
<h2>NLTK ngram functions<a class="headerlink" href="#nltk-ngram-functions" title="Link to this heading">#</a></h2>
<p>There are several functions in NLTK that you can use. We start with <code class="docutils literal notranslate"><span class="pre">nltk.bigrams()</span></code>. It takes a list of tokens as input and gives you all the possible bigrams of words. Then we can compute the frequency distribution of those bigrams.</p>
<p>But the best function is <code class="docutils literal notranslate"><span class="pre">everygrams</span></code>, which builds as many ngrams as you like from an input. You give it word tokens (but it can also be used with character tokens) and tell it how many types of ngrams to build. In my example, I say <code class="docutils literal notranslate"><span class="pre">1,</span> <span class="pre">3</span></code>, which means: give me: unigrams, bigrams, trigrams.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sent1</span> <span class="o">=</span> <span class="s2">&quot;I really like you.&quot;</span>

<span class="n">sent1_tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent1</span><span class="p">)</span>

<span class="n">sent1_bi</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">bigrams</span><span class="p">(</span><span class="n">sent1_tokens</span><span class="p">)</span>

<span class="c1"># compute frequency distribution for all the bigrams in the text</span>
<span class="n">sent1_fdist</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">sent1_bi</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sent1_fdist</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;I&#39;, &#39;really&#39;) 1
(&#39;really&#39;, &#39;like&#39;) 1
(&#39;like&#39;, &#39;you&#39;) 1
(&#39;you&#39;, &#39;.&#39;) 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># same, with another sentence</span>
<span class="c1"># note that &quot;really really&quot; now has a frequency of 2</span>

<span class="n">sent2</span> <span class="o">=</span> <span class="s2">&quot;I really really really very much like you.&quot;</span>

<span class="n">sent2_tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent2</span><span class="p">)</span>

<span class="n">sent2_bi</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">bigrams</span><span class="p">(</span><span class="n">sent2_tokens</span><span class="p">)</span>

<span class="n">sent2_fdist</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">sent2_bi</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sent2_fdist</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;I&#39;, &#39;really&#39;) 1
(&#39;really&#39;, &#39;really&#39;) 2
(&#39;really&#39;, &#39;very&#39;) 1
(&#39;very&#39;, &#39;much&#39;) 1
(&#39;much&#39;, &#39;like&#39;) 1
(&#39;like&#39;, &#39;you&#39;) 1
(&#39;you&#39;, &#39;.&#39;) 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># now, everygrams for sent1</span>

<span class="n">sent1_every</span> <span class="o">=</span> <span class="n">everygrams</span><span class="p">(</span><span class="n">sent1_tokens</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">sent1_every</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;I&#39;,),
 (&#39;I&#39;, &#39;really&#39;),
 (&#39;I&#39;, &#39;really&#39;, &#39;like&#39;),
 (&#39;really&#39;,),
 (&#39;really&#39;, &#39;like&#39;),
 (&#39;really&#39;, &#39;like&#39;, &#39;you&#39;),
 (&#39;like&#39;,),
 (&#39;like&#39;, &#39;you&#39;),
 (&#39;like&#39;, &#39;you&#39;, &#39;.&#39;),
 (&#39;you&#39;,),
 (&#39;you&#39;, &#39;.&#39;),
 (&#39;.&#39;,)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># build everygrams for sent2</span>
<span class="c1"># you can also build them of different length (1-2, 1-3, 1-4, etc)</span>
<span class="c1"># and you can try your own sentences</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="calculating-ngram-frequencies-from-reuters">
<h2>Calculating ngram frequencies from Reuters<a class="headerlink" href="#calculating-ngram-frequencies-from-reuters" title="Link to this heading">#</a></h2>
<p>Ngrams are really useful when we have large numbers of them and their frequencies. In this part, we take all the sentences in the Reuters corpus and count their frequencies. Then, we create a <code class="docutils literal notranslate"><span class="pre">removal_list</span></code> with all the things that we want to strip (punctuation and stopwords). Then, we create the lists of unigrams,  of bigrams and trigrams, padding to the left and to the right. Padding just means adding a special “word” that indicates the beginning and end of a sentence, so that the first and last words also participate in all possible bigrams.</p>
<p>For instance, in <em>I really like you</em>, we could have the following bigrams:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">I</span><span class="p">,</span> <span class="n">really</span>
<span class="n">really</span><span class="p">,</span> <span class="n">like</span>
<span class="n">like</span><span class="p">,</span> <span class="n">you</span>
</pre></div>
</div>
<p>But notice how, unlike the other words, <em>I</em> and <em>you</em> only participate in one bigram. We want to know that that’s because they are the beginning and end of the sentence. Padding adds that information, which here I am representing with the html code <code class="docutils literal notranslate"><span class="pre">&lt;s&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;/s&gt;</span></code>. So then we create the following bigrams:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">s</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">I</span>
<span class="n">I</span><span class="p">,</span> <span class="n">really</span>
<span class="n">really</span><span class="p">,</span> <span class="n">like</span>
<span class="n">like</span><span class="p">,</span> <span class="n">you</span>
<span class="n">you</span><span class="p">,</span> <span class="o">&lt;/</span><span class="n">s</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>So, we will first create a set of removal words, punctuation and stopwords that we don’t want to include the in the lists of ngrams. You can see what it contains below.</p>
<p>Next, we import the Reuters sentences and use <code class="docutils literal notranslate"><span class="pre">everygrams</span></code> to create unigrams, bigrams, and trigrams. We remove those that have words in the removal list.</p>
<p>After that, <code class="docutils literal notranslate"><span class="pre">word_salad</span></code>is a dictionary with the frequency distribution of those ngrams.</p>
<p>Finally, we use <code class="docutils literal notranslate"><span class="pre">word_salad</span></code> to create a sequence of segments that start with a certain prompt. The segments are made up of the prompt, plus the most likely next word. Thus, if the prompt is “it will”, then we’ll get the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;be&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;pay&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;not&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;IT&#39;</span><span class="p">,</span> <span class="s1">&#39;WILL&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;continue&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;have&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;make&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;take&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;be&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;raise&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;acquire&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;also&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;report&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;offer&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;issue&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;receive&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;increase&#39;</span><span class="p">),</span> 
<span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;sell&#39;</span><span class="p">),</span>
 <span class="n">etc</span><span class="o">.</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the list of things we&#39;ll remove (some punctuation, stopwords, and end of line codes)</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="n">my_punctuation</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span> <span class="o">+</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="s1">&#39;-&#39;</span><span class="o">+</span><span class="s1">&#39;&#39;&#39;+&#39;&#39;&#39;</span><span class="o">+</span><span class="s1">&#39;—&#39;</span>
<span class="n">removal_list</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stop_words</span><span class="p">)</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">my_punctuation</span><span class="p">)</span> <span class="o">|</span> <span class="p">{</span><span class="s1">&#39;lt&#39;</span><span class="p">,</span><span class="s1">&#39;rt&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">removal_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>234
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># just check what&#39;s in that list</span>
<span class="n">removal_list</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;\n&#39;,
 &#39;!&#39;,
 &#39;&quot;&#39;,
 &#39;#&#39;,
 &#39;$&#39;,
 &#39;%&#39;,
 &#39;&amp;&#39;,
 &quot;&#39;&quot;,
 &#39;(&#39;,
 &#39;)&#39;,
 &#39;*&#39;,
 &#39;+&#39;,
 &#39;,&#39;,
 &#39;-&#39;,
 &#39;.&#39;,
 &#39;/&#39;,
 &#39;:&#39;,
 &#39;;&#39;,
 &#39;&lt;&#39;,
 &#39;=&#39;,
 &#39;&gt;&#39;,
 &#39;?&#39;,
 &#39;@&#39;,
 &#39;[&#39;,
 &#39;\\&#39;,
 &#39;]&#39;,
 &#39;^&#39;,
 &#39;_&#39;,
 &#39;`&#39;,
 &#39;a&#39;,
 &#39;about&#39;,
 &#39;above&#39;,
 &#39;after&#39;,
 &#39;again&#39;,
 &#39;against&#39;,
 &#39;ain&#39;,
 &#39;all&#39;,
 &#39;am&#39;,
 &#39;an&#39;,
 &#39;and&#39;,
 &#39;any&#39;,
 &#39;are&#39;,
 &#39;aren&#39;,
 &quot;aren&#39;t&quot;,
 &#39;as&#39;,
 &#39;at&#39;,
 &#39;be&#39;,
 &#39;because&#39;,
 &#39;been&#39;,
 &#39;before&#39;,
 &#39;being&#39;,
 &#39;below&#39;,
 &#39;between&#39;,
 &#39;both&#39;,
 &#39;but&#39;,
 &#39;by&#39;,
 &#39;can&#39;,
 &#39;couldn&#39;,
 &quot;couldn&#39;t&quot;,
 &#39;d&#39;,
 &#39;did&#39;,
 &#39;didn&#39;,
 &quot;didn&#39;t&quot;,
 &#39;do&#39;,
 &#39;does&#39;,
 &#39;doesn&#39;,
 &quot;doesn&#39;t&quot;,
 &#39;doing&#39;,
 &#39;don&#39;,
 &quot;don&#39;t&quot;,
 &#39;down&#39;,
 &#39;during&#39;,
 &#39;each&#39;,
 &#39;few&#39;,
 &#39;for&#39;,
 &#39;from&#39;,
 &#39;further&#39;,
 &#39;had&#39;,
 &#39;hadn&#39;,
 &quot;hadn&#39;t&quot;,
 &#39;has&#39;,
 &#39;hasn&#39;,
 &quot;hasn&#39;t&quot;,
 &#39;have&#39;,
 &#39;haven&#39;,
 &quot;haven&#39;t&quot;,
 &#39;having&#39;,
 &#39;he&#39;,
 &quot;he&#39;d&quot;,
 &quot;he&#39;ll&quot;,
 &quot;he&#39;s&quot;,
 &#39;her&#39;,
 &#39;here&#39;,
 &#39;hers&#39;,
 &#39;herself&#39;,
 &#39;him&#39;,
 &#39;himself&#39;,
 &#39;his&#39;,
 &#39;how&#39;,
 &#39;i&#39;,
 &quot;i&#39;d&quot;,
 &quot;i&#39;ll&quot;,
 &quot;i&#39;m&quot;,
 &quot;i&#39;ve&quot;,
 &#39;if&#39;,
 &#39;in&#39;,
 &#39;into&#39;,
 &#39;is&#39;,
 &#39;isn&#39;,
 &quot;isn&#39;t&quot;,
 &#39;it&#39;,
 &quot;it&#39;d&quot;,
 &quot;it&#39;ll&quot;,
 &quot;it&#39;s&quot;,
 &#39;its&#39;,
 &#39;itself&#39;,
 &#39;just&#39;,
 &#39;ll&#39;,
 &#39;lt&#39;,
 &#39;m&#39;,
 &#39;ma&#39;,
 &#39;me&#39;,
 &#39;mightn&#39;,
 &quot;mightn&#39;t&quot;,
 &#39;more&#39;,
 &#39;most&#39;,
 &#39;mustn&#39;,
 &quot;mustn&#39;t&quot;,
 &#39;my&#39;,
 &#39;myself&#39;,
 &#39;needn&#39;,
 &quot;needn&#39;t&quot;,
 &#39;no&#39;,
 &#39;nor&#39;,
 &#39;not&#39;,
 &#39;now&#39;,
 &#39;o&#39;,
 &#39;of&#39;,
 &#39;off&#39;,
 &#39;on&#39;,
 &#39;once&#39;,
 &#39;only&#39;,
 &#39;or&#39;,
 &#39;other&#39;,
 &#39;our&#39;,
 &#39;ours&#39;,
 &#39;ourselves&#39;,
 &#39;out&#39;,
 &#39;over&#39;,
 &#39;own&#39;,
 &#39;re&#39;,
 &#39;rt&#39;,
 &#39;s&#39;,
 &#39;same&#39;,
 &#39;shan&#39;,
 &quot;shan&#39;t&quot;,
 &#39;she&#39;,
 &quot;she&#39;d&quot;,
 &quot;she&#39;ll&quot;,
 &quot;she&#39;s&quot;,
 &#39;should&#39;,
 &quot;should&#39;ve&quot;,
 &#39;shouldn&#39;,
 &quot;shouldn&#39;t&quot;,
 &#39;so&#39;,
 &#39;some&#39;,
 &#39;such&#39;,
 &#39;t&#39;,
 &#39;than&#39;,
 &#39;that&#39;,
 &quot;that&#39;ll&quot;,
 &#39;the&#39;,
 &#39;their&#39;,
 &#39;theirs&#39;,
 &#39;them&#39;,
 &#39;themselves&#39;,
 &#39;then&#39;,
 &#39;there&#39;,
 &#39;these&#39;,
 &#39;they&#39;,
 &quot;they&#39;d&quot;,
 &quot;they&#39;ll&quot;,
 &quot;they&#39;re&quot;,
 &quot;they&#39;ve&quot;,
 &#39;this&#39;,
 &#39;those&#39;,
 &#39;through&#39;,
 &#39;to&#39;,
 &#39;too&#39;,
 &#39;under&#39;,
 &#39;until&#39;,
 &#39;up&#39;,
 &#39;ve&#39;,
 &#39;very&#39;,
 &#39;was&#39;,
 &#39;wasn&#39;,
 &quot;wasn&#39;t&quot;,
 &#39;we&#39;,
 &quot;we&#39;d&quot;,
 &quot;we&#39;ll&quot;,
 &quot;we&#39;re&quot;,
 &quot;we&#39;ve&quot;,
 &#39;were&#39;,
 &#39;weren&#39;,
 &quot;weren&#39;t&quot;,
 &#39;what&#39;,
 &#39;when&#39;,
 &#39;where&#39;,
 &#39;which&#39;,
 &#39;while&#39;,
 &#39;who&#39;,
 &#39;whom&#39;,
 &#39;why&#39;,
 &#39;will&#39;,
 &#39;with&#39;,
 &#39;won&#39;,
 &quot;won&#39;t&quot;,
 &#39;wouldn&#39;,
 &quot;wouldn&#39;t&quot;,
 &#39;y&#39;,
 &#39;you&#39;,
 &quot;you&#39;d&quot;,
 &quot;you&#39;ll&quot;,
 &quot;you&#39;re&quot;,
 &quot;you&#39;ve&quot;,
 &#39;your&#39;,
 &#39;yours&#39;,
 &#39;yourself&#39;,
 &#39;yourselves&#39;,
 &#39;{&#39;,
 &#39;|&#39;,
 &#39;}&#39;,
 &#39;~&#39;,
 &#39;—&#39;}
</pre></div>
</div>
</div>
</div>
</section>
<section id="import-data-to-create-ngrams">
<h2>Import data to create ngrams<a class="headerlink" href="#import-data-to-create-ngrams" title="Link to this heading">#</a></h2>
<p>Here, we will use the <a class="reference external" href="https://www.nltk.org/book/ch02.html#reuters-corpus">Reuters corpus</a>. After you import it into <code class="docutils literal notranslate"><span class="pre">sents</span></code>, check its contents. You’ll see that it’s a list of sentences, and then a list of words in those sentences.</p>
<p>NOTE for lab: If you are going to do this with regular text data (text that you read from a file), you need to first tokenize each sentence. You can use code like the following, given that the text you read from the file is called <code class="docutils literal notranslate"><span class="pre">text_from_file</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">text_tokenized</span> <span class="pre">=</span> <span class="pre">word_tokenize(text_from_file)</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import Reuters and inspect it</span>
<span class="n">sents</span> <span class="o">=</span> <span class="n">reuters</span><span class="o">.</span><span class="n">sents</span><span class="p">()</span>
<span class="n">sents</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;ASIAN&#39;, &#39;EXPORTERS&#39;, &#39;FEAR&#39;, &#39;DAMAGE&#39;, &#39;FROM&#39;, &#39;U&#39;, &#39;.&#39;, &#39;S&#39;, &#39;.-&#39;, &#39;JAPAN&#39;, &#39;RIFT&#39;, &#39;Mounting&#39;, &#39;trade&#39;, &#39;friction&#39;, &#39;between&#39;, &#39;the&#39;, &#39;U&#39;, &#39;.&#39;, &#39;S&#39;, &#39;.&#39;, &#39;And&#39;, &#39;Japan&#39;, &#39;has&#39;, &#39;raised&#39;, &#39;fears&#39;, &#39;among&#39;, &#39;many&#39;, &#39;of&#39;, &#39;Asia&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;exporting&#39;, &#39;nations&#39;, &#39;that&#39;, &#39;the&#39;, &#39;row&#39;, &#39;could&#39;, &#39;inflict&#39;, &#39;far&#39;, &#39;-&#39;, &#39;reaching&#39;, &#39;economic&#39;, &#39;damage&#39;, &#39;,&#39;, &#39;businessmen&#39;, &#39;and&#39;, &#39;officials&#39;, &#39;said&#39;, &#39;.&#39;], [&#39;They&#39;, &#39;told&#39;, &#39;Reuter&#39;, &#39;correspondents&#39;, &#39;in&#39;, &#39;Asian&#39;, &#39;capitals&#39;, &#39;a&#39;, &#39;U&#39;, &#39;.&#39;, &#39;S&#39;, &#39;.&#39;, &#39;Move&#39;, &#39;against&#39;, &#39;Japan&#39;, &#39;might&#39;, &#39;boost&#39;, &#39;protectionist&#39;, &#39;sentiment&#39;, &#39;in&#39;, &#39;the&#39;, &#39;U&#39;, &#39;.&#39;, &#39;S&#39;, &#39;.&#39;, &#39;And&#39;, &#39;lead&#39;, &#39;to&#39;, &#39;curbs&#39;, &#39;on&#39;, &#39;American&#39;, &#39;imports&#39;, &#39;of&#39;, &#39;their&#39;, &#39;products&#39;, &#39;.&#39;], ...]
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-and-use-a-function-to-clean-the-text">
<h2>Define and use a function to clean the text<a class="headerlink" href="#define-and-use-a-function-to-clean-the-text" title="Link to this heading">#</a></h2>
<p>This function <strong>flattens</strong> the list of sentences, which are in turn a list of words, and flattens them to simply a list of words. This is because Reuters provides a list of sentences. For plain text, you’d skip the ‘flattened’ part of this function.</p>
<p>Then, call the function to clean the text and remove all the stopwords, punctuation, etc., that are in the <code class="docutils literal notranslate"><span class="pre">removal_list</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">clean_flattened_sentences</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="c1"># flatten the list of sentences into a single list of words</span>
    <span class="n">flattened</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">]</span>
    
    <span class="c1"># clean the flattened list by removing stop words and punctuation</span>
    <span class="n">cleaned_flattened</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">flattened</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">removal_list</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">cleaned_flattened</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># call the function</span>
<span class="n">cleaned_flat_sentences</span> <span class="o">=</span> <span class="n">clean_flattened_sentences</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the first 50 cleaned words, just to inspect the list</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cleaned_flat_sentences</span><span class="p">[:</span><span class="mi">50</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;ASIAN&#39;, &#39;EXPORTERS&#39;, &#39;FEAR&#39;, &#39;DAMAGE&#39;, &#39;FROM&#39;, &#39;U&#39;, &#39;S&#39;, &#39;.-&#39;, &#39;JAPAN&#39;, &#39;RIFT&#39;, &#39;Mounting&#39;, &#39;trade&#39;, &#39;friction&#39;, &#39;U&#39;, &#39;S&#39;, &#39;And&#39;, &#39;Japan&#39;, &#39;raised&#39;, &#39;fears&#39;, &#39;among&#39;, &#39;many&#39;, &#39;Asia&#39;, &#39;exporting&#39;, &#39;nations&#39;, &#39;row&#39;, &#39;could&#39;, &#39;inflict&#39;, &#39;far&#39;, &#39;reaching&#39;, &#39;economic&#39;, &#39;damage&#39;, &#39;businessmen&#39;, &#39;officials&#39;, &#39;said&#39;, &#39;They&#39;, &#39;told&#39;, &#39;Reuter&#39;, &#39;correspondents&#39;, &#39;Asian&#39;, &#39;capitals&#39;, &#39;U&#39;, &#39;S&#39;, &#39;Move&#39;, &#39;Japan&#39;, &#39;might&#39;, &#39;boost&#39;, &#39;protectionist&#39;, &#39;sentiment&#39;, &#39;U&#39;, &#39;S&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-everygrams-and-create-a-dictionary">
<h2>Run everygrams and create a dictionary<a class="headerlink" href="#run-everygrams-and-create-a-dictionary" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">everygrams()</span></code> creates a list of all the unigram, bigram, trigram combinations in the text. Then, we use <code class="docutils literal notranslate"><span class="pre">FreqDist()</span></code> to create a dictionary with the frequency of each of those ngrams.</p>
<section id="warning">
<h3>Warning<a class="headerlink" href="#warning" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">one_two_three_ngrams</span></code> is a <a class="reference external" href="https://realpython.com/introduction-to-python-generators/">generator</a> (see what happens when I say <code class="docutils literal notranslate"><span class="pre">type(one_two_thre_ngrams()</span></code>), so you shouldn’t try to print it or inspect it before you do the FreqDist. Just run the next two lines one after the other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the ngrams</span>
<span class="n">one_two_three_ngrams</span> <span class="o">=</span> <span class="n">everygrams</span><span class="p">(</span><span class="n">cleaned_flat_sentences</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_right</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a dictionary with the frequency of all the ngrams</span>
<span class="n">word_salad</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">one_two_three_ngrams</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is just so that you know this variable is a generator</span>
<span class="nb">type</span><span class="p">(</span><span class="n">one_two_three_ngrams</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>generator
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># inspect the word salad. It should be a dictionary</span>
<span class="n">word_salad</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FreqDist({(&#39;said&#39;,): 25224, (&#39;mln&#39;,): 18037, (&#39;vs&#39;,): 14120, (&#39;dlrs&#39;,): 11730, (&#39;The&#39;,): 10968, (&#39;000&#39;,): 10277, (&#39;1&#39;,): 9977, (&#39;pct&#39;,): 9093, (&#39;cts&#39;,): 7953, (&#39;2&#39;,): 6528, ...})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sort the dictionary in reverse order (the result is a list, but that&#39;s fine, as we only want to see it)</span>
<span class="n">word_salad_ordered</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_salad</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the first 20 items</span>
<span class="n">word_salad_ordered</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[((&#39;said&#39;,), 25224),
 ((&#39;mln&#39;,), 18037),
 ((&#39;vs&#39;,), 14120),
 ((&#39;dlrs&#39;,), 11730),
 ((&#39;The&#39;,), 10968),
 ((&#39;000&#39;,), 10277),
 ((&#39;1&#39;,), 9977),
 ((&#39;pct&#39;,), 9093),
 ((&#39;cts&#39;,), 7953),
 ((&#39;2&#39;,), 6528),
 ((&#39;U&#39;,), 6388),
 ((&#39;S&#39;,), 6382),
 ((&#39;year&#39;,), 6310),
 ((&#39;U&#39;, &#39;S&#39;), 5694),
 ((&#39;billion&#39;,), 5652),
 ((&#39;3&#39;,), 5091),
 ((&#39;5&#39;,), 4683),
 ((&#39;would&#39;,), 4634),
 ((&#39;loss&#39;,), 4528),
 ((&#39;company&#39;,), 4399)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the last 20 items</span>
<span class="n">word_salad_ordered</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[((&#39;one&#39;, &#39;mln&#39;, &#39;A&#39;), 1),
 ((&#39;A&#39;, &#39;H&#39;, &#39;A&#39;), 1),
 ((&#39;H&#39;, &#39;A&#39;), 1),
 ((&#39;H&#39;, &#39;A&#39;, &#39;AUTOMOTIVE&#39;), 1),
 ((&#39;A&#39;, &#39;AUTOMOTIVE&#39;), 1),
 ((&#39;A&#39;, &#39;AUTOMOTIVE&#39;, &#39;TECHNOLOGIES&#39;), 1),
 ((&#39;AUTOMOTIVE&#39;, &#39;TECHNOLOGIES&#39;), 1),
 ((&#39;AUTOMOTIVE&#39;, &#39;TECHNOLOGIES&#39;, &#39;CORP&#39;), 1),
 ((&#39;TECHNOLOGIES&#39;, &#39;CORP&#39;, &#39;YEAR&#39;), 1),
 ((&#39;52&#39;, &#39;cts&#39;, &#39;Shr&#39;), 1),
 ((&#39;Shr&#39;, &#39;diluted&#39;, &#39;41&#39;), 1),
 ((&#39;diluted&#39;, &#39;41&#39;), 1),
 ((&#39;diluted&#39;, &#39;41&#39;, &#39;cts&#39;), 1),
 ((&#39;Net&#39;, &#39;1&#39;, &#39;916&#39;), 1),
 ((&#39;1&#39;, &#39;916&#39;), 1),
 ((&#39;1&#39;, &#39;916&#39;, &#39;000&#39;), 1),
 ((&#39;vs&#39;, &#39;2&#39;, &#39;281&#39;), 1),
 ((&#39;6&#39;, &#39;mln&#39;, None), 1),
 ((&#39;mln&#39;, None), 1),
 ((&#39;mln&#39;, None, None), 1)]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="generating-text-from-the-word-salad-lists">
<h2>Generating text from the word salad lists<a class="headerlink" href="#generating-text-from-the-word-salad-lists" title="Link to this heading">#</a></h2>
<p>I can give the list of ngrams a prefix, or a ‘prompt’, and it will give me all the possible things that come after it. This is just an unordered list, but you can also order it by the most frequent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># given an input &quot;prompt&quot;</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;company loss&#39;</span>

<span class="c1"># Check what&#39;s most likely to come next</span>
<span class="c1"># make sure there are no None values</span>
<span class="n">matching_ngrams</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ng</span> <span class="k">for</span> <span class="n">ng</span> <span class="ow">in</span> <span class="n">word_salad</span> 
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">word</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">ng</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ng</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">prefix</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">matching_ngrams</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;company&#39;, &#39;loss&#39;), (&#39;company&#39;, &#39;loss&#39;, &#39;2&#39;), (&#39;company&#39;, &#39;losses&#39;), (&#39;company&#39;, &#39;losses&#39;, &#39;largely&#39;), (&#39;company&#39;, &#39;loss&#39;, &#39;several&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># try a different prompt</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;they said&#39;</span>

<span class="n">matching_ngrams</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ng</span> <span class="k">for</span> <span class="n">ng</span> <span class="ow">in</span> <span class="n">word_salad</span> 
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">word</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">ng</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ng</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">prefix</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">matching_ngrams</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;They&#39;, &#39;said&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Fed&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;would&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;market&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;expect&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Saudi&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;central&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;believed&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;sunflower&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;despite&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;reduction&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;EC&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;agreement&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;expected&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Japanese&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Japan&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;0&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;likely&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;production&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;export&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;open&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Brazil&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Chung&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;move&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;saw&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;maritime&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;department&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;plan&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;French&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;bank&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;MITI&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;could&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;shipment&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;new&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;shares&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;producers&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;looking&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;dollar&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;similar&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;size&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;approval&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;price&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;hogs&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;71&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;sharp&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;traders&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;mainly&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;commission&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Soviet&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;even&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;rumors&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;relaxation&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;deregulation&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Lukman&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;president&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;voluntary&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Nigeria&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;overseas&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;CPC&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;prices&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;initial&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Ali&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;country&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;American&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;without&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Citicorp&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Trailways&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;imports&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;threatened&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;envoy&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;closure&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Iranian&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;banks&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;special&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;real&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Standard&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;fear&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Sri&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;record&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;information&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;25&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Reaan&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;IDB&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;crushers&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;drilling&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;major&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;IBC&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;government&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Pioneer&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;CP&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;stocks&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;stock&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;tell&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;stabilizes&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;venture&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Chirac&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;lower&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;come&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Prime&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Ministry&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;significant&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;however&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;heard&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;last&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;may&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;another&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;recent&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;funds&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;cut&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;showed&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;USAir&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;call&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;exports&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;nine&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;revenues&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;increase&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;spent&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Chrysler&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;index&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;face&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;consumption&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;near&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;owning&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;seamen&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;import&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;confident&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Taft&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;cargo&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;spot&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Princeville&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;focusing&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;arrangement&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Australian&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;West&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;licences&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;airline&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;foreign&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;domestic&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;vast&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;1987&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;shocked&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;document&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;issues&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;make&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Continental&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;injuries&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;half&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;September&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;six&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;discussions&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;8&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Sudan&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;ministers&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;member&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Shultz&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;tax&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;firm&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;joint&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;gesture&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;companies&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;79&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;intervention&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;meetings&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;accord&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Bank&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;decision&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;due&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;Abu&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;financial&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;large&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;growers&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;might&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;mineral&#39;), (&#39;They&#39;, &#39;said&#39;, &#39;maximum&#39;)]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h1>
<p>We have learned a basic principle of generative AI: to predict the next word in a sequence based on a corpus.</p>
<p>Note that ngrams are not actually generative AI. LLMs use vector embeddings instead of word representations (tokens).</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Week_07.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Ling 380 - Week 7</p>
      </div>
    </a>
    <a class="right-next"
       href="Week_09.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ling 380 - Week 9</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Ling 380 - Week 8</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-ai">Generative AI</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-ngrams">Calculating ngrams</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-statements">Import statements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nltk-ngram-functions">NLTK ngram functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-ngram-frequencies-from-reuters">Calculating ngram frequencies from Reuters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-data-to-create-ngrams">Import data to create ngrams</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-and-use-a-function-to-clean-the-text">Define and use a function to clean the text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-everygrams-and-create-a-dictionary">Run everygrams and create a dictionary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warning">Warning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-text-from-the-word-salad-lists">Generating text from the word salad lists</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>