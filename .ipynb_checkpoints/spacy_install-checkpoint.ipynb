{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing spaCy\n",
    "\n",
    "SpaCy is a set of tools for Natural Language Processing. For more info: [spaCy](https://spacy.io/).\n",
    "\n",
    "This notebook will help you install it, but you can also go to the [installation instructions](https://spacy.io/usage) for the best version for your system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways of installing spaCy\n",
    "\n",
    "### 1. Jupyter notebook\n",
    "You can install it from the notebook, by running the 2 lines below in your Jupyter notebook. Remember you only have to do this once. \n",
    "\n",
    "### 2. Command prompt\n",
    "* In Windows, if you have Anaconda, you can open an Anaconda powershell prompt. If you don't have Anaconda, just open a Windows powershell in admin mode.\n",
    "* On a Mac, open a terminal window (spotlight and type \"terminal\"). Or look for \"terminal\" in your apps folder. \n",
    "\n",
    "Now that you have a command window open, simply go to the spaCy website and choose your operating system to copy and paste the right commands (one at a time). Click on the right options for you from here: https://spacy.io/usage  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatibility problems\n",
    "If you get an error that says something about numpy, you can do two things, below.\n",
    "\n",
    "Possible error messages:\n",
    "* numpy.ndarray ...\n",
    "* numpy.dtype ...\n",
    "\n",
    "### 1. Follow instructions on the spaCy site\n",
    "Go to the heading \"Using build constraints when compiling from source\" in https://spacy.io/usage. In a command prompt/terminal, type the two lines (one at a time) that start with `PIP_CONSTRAINT`.\n",
    "\n",
    "### 2. Downgrade numpy\n",
    "Type one of the two commands below, either in a notebook or in terminal/command prompt:\n",
    "\n",
    "* In notebook: `!pip install numpy==1.26.4`\n",
    "* In command prompt: `pip install numpy==1.26.4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing spaCy and language model\n",
    "\n",
    "If running this notebook locally, you'll only have to do the next two lines once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading spaCy and language model\n",
    "Installation (if local) only needs to be done once. However, you need to import the spaCy module and load the language model every time you want to use it. \n",
    "\n",
    "Here, we are loading the small model for English derived from web data. There are other [models](https://spacy.io/usage/models) for English and for other languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing installation\n",
    "\n",
    "We'll define a sentence, process it with spaCy and check the output. This will test whether all the components are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is a test sentence about Canada, but you can type whatever you want here.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting string to doc with spaCy\n",
    "spaCy has a special type of object, a `Doc`. It's the entire processing pipeline for any NLP system, in a single object. It takes a text, e.g., `sent1` and applies all the NLP steps to it (tokenization, tagging, named entity recognition). Once you have converted a string (a sentence) or a whole text to Doc, you can access everything that spaCy has done with it, i.e., the entire structure of language information that it has applied to it, with labels. spaCy refers to that language information and labels as 'linguistic annotations'. spaCy does this with a simple function, `nlp()`.\n",
    "\n",
    "![spaCy pipeline](https://spacy.io/images/pipeline.svg)\n",
    "\n",
    "Image from https://spacy.io/usage/processing-pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accesing the information in the Doc object\n",
    "\n",
    "`doc` contains lots of [useful information](https://spacy.io/api/doc):\n",
    "\n",
    "* tokens (words)\n",
    "* lemmas\n",
    "* morphology\n",
    "* part of speech tags (pos tags) \n",
    "* syntactic structure (a parse tree)\n",
    "* named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print word tokens\n",
    "\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas\n",
    "\n",
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphology\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tags (more on this below)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# named entities\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
