{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeaf6ac1",
   "metadata": {},
   "source": [
    "# Ling 380 - Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95126350",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "Sentiment analysis is a computational method to extract 'sentiment' from text. What 'sentiment' means varies, but in general, it is the positive or negative opinion about something that is conveyed in the text.\n",
    "\n",
    "The most basic methods have a dictionary of positive and negative words and then check to see how many of those are in the text in question. You can do fancy calculations, but a difference or relative proportion is common. \n",
    "\n",
    "Sentiment analysis is used widely, from online posts and reviews to survey data and news. There are many issues with using it without fully understanding what the numbers mean. Do check the reading on Canvas to explore more about it: \n",
    "\n",
    "* Taboada, M. (2016) [Sentiment analysis: An overview from linguistics](https://www.annualreviews.org/content/journals/10.1146/annurev-linguistics-011415-040518). _Annual Review of Linguistics_ 2: 325-347."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3841b",
   "metadata": {},
   "source": [
    "# Sentiment analysis with VADER\n",
    "\n",
    "[VADER](https://github.com/cjhutto/vaderSentiment) is a lexicon-based system for sentiment analysis. It takes a text (or post, headline, etc.) and provides two scores:\n",
    "\n",
    "* Proportion of the text with positive, negative, or neutral words\n",
    "  * This just counts the words in the text that are also in the [dictionary](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) and calculates the ratio\n",
    "* Composite score\n",
    "  * Calculated using the [dictionary](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt), plus applying a set of rules to deal with negation and other linguistic phenomena that may change the score\n",
    "\n",
    "\n",
    "There is an implementation of VADER in NLTK, so we will use that version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250bcb3",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4307fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abb5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c576c8",
   "metadata": {},
   "source": [
    "## Try with toy sentences\n",
    "\n",
    "A couple of toy sentences and a list of examples from the VADER repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ad5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.4201}\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"I really like you.\"\n",
    "\n",
    "print(analyzer.polarity_scores(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b54176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.664, 'pos': 0.336, 'compound': 0.4664}\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"I really really really very much like you.\"\n",
    "\n",
    "print(analyzer.polarity_scores(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a4ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.642, 'neu': 0.146, 'pos': 0.212, 'compound': -0.7096}\n"
     ]
    }
   ],
   "source": [
    "sent3 = \"I had a horrible, terrible, no good day\"\n",
    "\n",
    "print(analyzer.polarity_scores(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fefe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'compound': -0.3412}\n"
     ]
    }
   ],
   "source": [
    "sent3 = \"I haven't read a better book\"\n",
    "\n",
    "print(analyzer.polarity_scores(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84987a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f465d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are sample sentences from VADER\n",
    "sentences = [\"VADER is smart, handsome, and funny.\",  # positive sentence example\n",
    "             \"VADER is smart, handsome, and funny!\",  # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    "             \"VADER is very smart, handsome, and funny.\", # booster words handled correctly (sentiment intensity adjusted)\n",
    "             \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
    "             \"VADER is VERY SMART, handsome, and FUNNY!!!\", # combination of signals - VADER appropriately adjusts intensity\n",
    "             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\", # booster words & punctuation make this close to ceiling for score\n",
    "             \"VADER is not smart, handsome, nor funny.\",  # negation sentence example\n",
    "             \"The book was good.\",  # positive sentence\n",
    "             \"At least it isn't a horrible book.\",  # negated negative sentence with contraction\n",
    "             \"The book was only kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n",
    "             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
    "             \"Today SUX!\",  # negative slang with capitalization emphasis\n",
    "             \"Today only kinda sux! But I'll get by, lol\", # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
    "             \"Make sure you :) or :D today!\",  # emoticons handled\n",
    "             \"Catch utf-8 emoji such as such as üíò and üíã and üòÅ\",  # emojis handled\n",
    "             \"Not bad at all\"  # Capitalized negation\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d321da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER is smart, handsome, and funny.------------------------ {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
      "VADER is smart, handsome, and funny!------------------------ {'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
      "VADER is very smart, handsome, and funny.------------------- {'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n",
      "VADER is VERY SMART, handsome, and FUNNY.------------------- {'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n",
      "VADER is VERY SMART, handsome, and FUNNY!!!----------------- {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n",
      "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!---- {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n",
      "VADER is not smart, handsome, nor funny.-------------------- {'neg': 0.646, 'neu': 0.354, 'pos': 0.0, 'compound': -0.7424}\n",
      "The book was good.------------------------------------------ {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "At least it isn't a horrible book.-------------------------- {'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n",
      "The book was only kind of good.----------------------------- {'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.3832}\n",
      "The plot was good, but the characters are uncompelling and the dialog is not great. {'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n",
      "Today SUX!-------------------------------------------------- {'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n",
      "Today only kinda sux! But I'll get by, lol------------------ {'neg': 0.127, 'neu': 0.556, 'pos': 0.317, 'compound': 0.5249}\n",
      "Make sure you :) or :D today!------------------------------- {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.8633}\n",
      "Catch utf-8 emoji such as such as üíò and üíã and üòÅ------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Not bad at all---------------------------------------------- {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<60} {}\".format(sentence, str(vs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70bd478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER is smart, handsome, and funny.\n",
      "    {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
      "VADER is smart, handsome, and funny!\n",
      "    {'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
      "VADER is very smart, handsome, and funny.\n",
      "    {'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n",
      "VADER is VERY SMART, handsome, and FUNNY.\n",
      "    {'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n",
      "VADER is VERY SMART, handsome, and FUNNY!!!\n",
      "    {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n",
      "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\n",
      "    {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n",
      "VADER is not smart, handsome, nor funny.\n",
      "    {'neg': 0.646, 'neu': 0.354, 'pos': 0.0, 'compound': -0.7424}\n",
      "The book was good.\n",
      "    {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "At least it isn't a horrible book.\n",
      "    {'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n",
      "The book was only kind of good.\n",
      "    {'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.3832}\n",
      "The plot was good, but the characters are uncompelling and the dialog is not great.\n",
      "    {'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n",
      "Today SUX!\n",
      "    {'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n",
      "Today only kinda sux! But I'll get by, lol\n",
      "    {'neg': 0.127, 'neu': 0.556, 'pos': 0.317, 'compound': 0.5249}\n",
      "Make sure you :) or :D today!\n",
      "    {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.8633}\n",
      "Catch utf-8 emoji such as such as üíò and üíã and üòÅ\n",
      "    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Not bad at all\n",
      "    {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "# another way to print\n",
    "for sentence in sentences:\n",
    "    scores = analyzer.polarity_scores(sentence)\n",
    "    print(sentence)\n",
    "    print(\"   \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0085f",
   "metadata": {},
   "source": [
    "## Movie reviews\n",
    "\n",
    "Next, we will analyze some movie reviews from the [SFU Review Corpus](https://www.sfu.ca/~mtaboada/SFU_Review_Corpus.html). They are in the 'reviews' directory. \n",
    "\n",
    "We will just do the usual process of defining a function to calculate the score and another function to process the directory and call the calculating function. Note that I am creating the analyzer here again. This is because you want to be able to run this function by itself, without the statement above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0204969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score\n",
    "\n",
    "def process_dir(path):\n",
    "    \"\"\"\n",
    "    Reads all the files in a directory. Processes them using the 'get_sentiment_scores' function\n",
    "    \n",
    "    Args: \n",
    "        path (str): path to the directory where the files are\n",
    "        \n",
    "    Returns:\n",
    "        dict: a dictionary with file names as keys and the tokens, types, lexical diversity, as values\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):    \n",
    "            file_path = os.path.join(path, filename)      \n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                scores[filename] = get_sentiment_scores(text)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140ae97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './reviews'\n",
    "\n",
    "scores_files = process_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6187886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gothika.txt': {'neg': 0.179, 'neu': 0.722, 'pos': 0.099, 'compound': -0.9938}, 'bad_santa.txt': {'neg': 0.135, 'neu': 0.693, 'pos': 0.172, 'compound': 0.9489}, 'cat_in_the_hat.txt': {'neg': 0.072, 'neu': 0.795, 'pos': 0.133, 'compound': 0.9882}, 'elf.txt': {'neg': 0.046, 'neu': 0.821, 'pos': 0.133, 'compound': 0.9868}}\n"
     ]
    }
   ],
   "source": [
    "print(scores_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d518bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gothika.txt</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.9938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_santa.txt</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.9489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_in_the_hat.txt</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elf.txt</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.9868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      neg    neu    pos  compound\n",
       "gothika.txt         0.179  0.722  0.099   -0.9938\n",
       "bad_santa.txt       0.135  0.693  0.172    0.9489\n",
       "cat_in_the_hat.txt  0.072  0.795  0.133    0.9882\n",
       "elf.txt             0.046  0.821  0.133    0.9868"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of course, pandas makes everything look better\n",
    "df = pandas.DataFrame.from_dict(scores_files, orient=\"index\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a28995",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We have learned about sentiment analysis and how to run a 'classic' method for sentiment, VADER. \n",
    "\n",
    "Read the files and compare the scores to the text in the files. Do you agree with what VADER says? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}